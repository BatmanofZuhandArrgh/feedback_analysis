{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I could do word frequency analysis, word cloud and such, and find which words correlate with lowest scores. But then, I'm sure \"bug\", \"crash\" will give low scores and \"good\", \"awesome\" will give high scores, and that doesn't really give any interesting insights.\n",
    "\n",
    "However, the BERTopic framework has all the bells and whistles I'm hoping for. First, it will produces embeddings for each document, then apply a dimensionality reduction, use a clustering algorithm, then extract the word importance for each clusters. This can be achieved using class-based TF-IDF, like normal TF-IDF, but applies on a cluster-level instead of document-level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
